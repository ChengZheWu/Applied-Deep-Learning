{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "data_folder = \"/data/NFS/andy_data/course/ADL/hw0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(pred, label):\n",
    "    err = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] != label[i]:\n",
    "            err += 1\n",
    "    return 1 - err/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(data_folder + \"/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 1)\n"
     ]
    }
   ],
   "source": [
    "category = df_train[\"Category\"].values[:, np.newaxis]\n",
    "print(category.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [00:01<00:00, 76155.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = df_train[\"text\"].values\n",
    "\n",
    "bag = {}\n",
    "num = 0\n",
    "for i in tqdm(range(len(text))):\n",
    "    for word in text[i].split(\" \"):\n",
    "        if word not in bag:\n",
    "            bag[word] = num\n",
    "            num+=1\n",
    "print(len(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [00:22<00:00, 3487.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 75418)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in tqdm(range(len(text))):\n",
    "    sub_data = np.zeros(len(bag), dtype=np.int8)\n",
    "    for w in text[i].split(\" \"):\n",
    "        if w in bag:\n",
    "            sub_data[bag[w]] += 1\n",
    "    data.append(sub_data)\n",
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70000, 75418]) torch.Size([70000, 1])\n",
      "torch.Size([10000, 75418]) torch.Size([10000, 1])\n"
     ]
    }
   ],
   "source": [
    "data = torch.FloatTensor(data)\n",
    "category = torch.FloatTensor(category)\n",
    "\n",
    "train_x = data[:70000]\n",
    "train_y = category[:70000]\n",
    "val_x = data[70000:80000]\n",
    "val_y = category[70000:80000]\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_set = TensorDataset(train_x, train_y)\n",
    "val_set = TensorDataset(val_x, val_y)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(75418, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/015] 15.77 sec(s) Train Loss: 0.6097 Acc: 0.6678| Val loss: 0.5498 Acc: 0.8622\n",
      "[002/015] 16.52 sec(s) Train Loss: 0.5070 Acc: 0.8576| Val loss: 0.4702 Acc: 0.8470\n",
      "[003/015] 15.80 sec(s) Train Loss: 0.4430 Acc: 0.8478| Val loss: 0.4230 Acc: 0.8449\n",
      "[004/015] 16.50 sec(s) Train Loss: 0.4017 Acc: 0.8549| Val loss: 0.3924 Acc: 0.8521\n",
      "[005/015] 16.33 sec(s) Train Loss: 0.3724 Acc: 0.8653| Val loss: 0.3708 Acc: 0.8638\n",
      "[006/015] 16.65 sec(s) Train Loss: 0.3488 Acc: 0.8804| Val loss: 0.3542 Acc: 0.8750\n",
      "[007/015] 16.82 sec(s) Train Loss: 0.3298 Acc: 0.8947| Val loss: 0.3413 Acc: 0.8853\n",
      "[008/015] 16.04 sec(s) Train Loss: 0.3133 Acc: 0.9074| Val loss: 0.3309 Acc: 0.8940\n",
      "[009/015] 16.76 sec(s) Train Loss: 0.2996 Acc: 0.9155| Val loss: 0.3237 Acc: 0.8992\n",
      "[010/015] 16.19 sec(s) Train Loss: 0.2870 Acc: 0.9210| Val loss: 0.3173 Acc: 0.8995\n",
      "[011/015] 16.10 sec(s) Train Loss: 0.2763 Acc: 0.9240| Val loss: 0.3129 Acc: 0.8999\n",
      "[012/015] 17.03 sec(s) Train Loss: 0.2664 Acc: 0.9264| Val loss: 0.3085 Acc: 0.9000\n",
      "[013/015] 16.17 sec(s) Train Loss: 0.2584 Acc: 0.9279| Val loss: 0.3072 Acc: 0.9008\n",
      "[014/015] 17.70 sec(s) Train Loss: 0.2505 Acc: 0.9297| Val loss: 0.3044 Acc: 0.9015\n",
      "[015/015] 15.62 sec(s) Train Loss: 0.2437 Acc: 0.9311| Val loss: 0.3033 Acc: 0.9028\n",
      "Time : 4 m 5.995944 s\n"
     ]
    }
   ],
   "source": [
    "model = NN().to(device)\n",
    "loss = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 15\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    val_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch[0].to(device)\n",
    "        targets = batch[1].to(device)\n",
    "        preds = model(inputs)\n",
    "        batch_loss = loss(preds, targets)\n",
    "        batch_loss.requires_grad_()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        preds = preds.data.cpu().numpy()\n",
    "        targets = targets.data.cpu().numpy()\n",
    "        \n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "        preds[preds>0.5] = 1\n",
    "        preds[preds!=1] = 0\n",
    "        train_acc += cal_acc(preds, targets)\n",
    "  \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            inputs = batch[0].to(device)\n",
    "            targets = batch[1].to(device)\n",
    "            preds = model(inputs)\n",
    "            batch_loss = loss(preds, targets)\n",
    "\n",
    "            preds = preds.data.cpu().numpy()\n",
    "            targets = targets.data.cpu().numpy()\n",
    "\n",
    "            val_loss += batch_loss.item()\n",
    "\n",
    "            preds[preds>0.5] = 1\n",
    "            preds[preds!=1] = 0\n",
    "            val_acc += cal_acc(preds, targets)\n",
    "    \n",
    "    train_loss /= train_loader.__len__()\n",
    "    val_loss /= val_loader.__len__()\n",
    "    train_acc /= train_loader.__len__()\n",
    "    val_acc /= val_loader.__len__()\n",
    "    \n",
    "    print('[%03d/%03d] %2.2f sec(s) Train Loss: %.4f Acc: %.4f| Val loss: %.4f Acc: %.4f' % \\\n",
    "        (epoch + 1, epochs, time.time()-epoch_start_time, \\\n",
    "         train_loss, train_acc, \\\n",
    "         val_loss, val_acc))\n",
    "    \n",
    "end = time.time()\n",
    "total_time = end - start\n",
    "print(\"Time : %d m %f s\" %(total_time // 60, total_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 3824.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 75418)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(data_folder + \"/test.csv\")\n",
    "text = df_test[\"text\"].values\n",
    "ids = df_test[\"Id\"].values\n",
    "\n",
    "data = []\n",
    "for i in tqdm(range(len(text))):\n",
    "    sub_data = np.zeros(len(bag), dtype=np.int8)\n",
    "    for w in text[i].split(\" \"):\n",
    "        if w in bag:\n",
    "            sub_data[bag[w]] += 1\n",
    "    data.append(sub_data)\n",
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.FloatTensor(data)\n",
    "\n",
    "batch_size = 512\n",
    "test_set = TensorDataset(test_x)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_y = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        inputs = batch[0].to(device)\n",
    "        preds = model(inputs)\n",
    "        for y in preds:\n",
    "            if y > 0.5:\n",
    "                y = 1\n",
    "            else:\n",
    "                y = 0\n",
    "            test_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(data_folder + \"/submit.csv\", \"w\")\n",
    "writer = csv.writer(f)\n",
    "writer.writerow([\"Id\", \"Category\"])\n",
    "for i in range(len(test_y)):\n",
    "    writer.writerow([ids[i], test_y[i]])\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
