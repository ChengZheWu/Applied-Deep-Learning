{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73197f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from slot_dataset import SeqClsDataset\n",
    "# from slot_model import SeqClassifier\n",
    "from utils import Vocab\n",
    "\n",
    "TRAIN = \"train\"\n",
    "DEV = \"eval\"\n",
    "SPLITS = [TRAIN, DEV]\n",
    "device = torch.device(\"cuda:2\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9202d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/slot/\"\n",
    "cache_dir = \"./cache/slot/\"\n",
    "ckpt_dir = \"./ckpt/slot/\"\n",
    "max_len = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c7125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(cache_dir + \"vocab.pkl\"), \"rb\") as f:\n",
    "    vocab: Vocab = pickle.load(f)\n",
    "\n",
    "tag_idx_path = Path(cache_dir + \"tag2idx.json\")\n",
    "tag2idx: Dict[str, int] = json.loads(tag_idx_path.read_text())\n",
    "\n",
    "data_paths = {split: Path(data_dir + \"%s.json\" %split) for split in SPLITS}\n",
    "data = {split: json.loads(path.read_text()) for split, path in data_paths.items()}\n",
    "datasets: Dict[str, SeqClsDataset] = {\n",
    "    split: SeqClsDataset(split_data, vocab, tag2idx, max_len)\n",
    "    for split, split_data in data.items()\n",
    "}\n",
    "    \n",
    "batch_size = 128\n",
    "train_loader = DataLoader(datasets[\"train\"], batch_size=batch_size, shuffle=True, collate_fn=datasets[\"train\"].collate_fn)\n",
    "val_loader = DataLoader(datasets[\"eval\"], batch_size=batch_size, shuffle=False, collate_fn=datasets[\"eval\"].collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07f2b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len = 0\n",
    "# for i in range(len(datasets[\"train\"].data)):\n",
    "#     sentence = datasets[\"train\"].data[i][\"tokens\"]\n",
    "#     if len(sentence) > max_len:\n",
    "#         max_len = len(sentence)\n",
    "# print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "605daa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c14d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding\n",
    "\n",
    "class SeqClassifier(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tag2idx,\n",
    "        embeddings: torch.tensor,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        dropout: float,\n",
    "        bidirectional: bool,\n",
    "        num_class: int,\n",
    "    ) -> None:\n",
    "        super(SeqClassifier, self).__init__()\n",
    "        self.tag2idx = tag2idx\n",
    "        self.num_class = num_class\n",
    "        self.embedding_dim = embeddings.size(1)\n",
    "        self.embed = Embedding.from_pretrained(embeddings, freeze=False)\n",
    "        self.rnn = nn.LSTM(input_size=self.embedding_dim, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                          dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
    "        if bidirectional:\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size*2, hidden_size),\n",
    "                nn.BatchNorm1d(35),\n",
    "                nn.Linear(hidden_size, num_class),\n",
    "                nn.Softmax(dim=2)\n",
    "            )\n",
    "        else:\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_size, num_class),\n",
    "                nn.Softmax(dim=2)\n",
    "            )\n",
    "            \n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.num_class, self.num_class))\n",
    "        \n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag2idx[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag2idx[STOP_TAG]] = -10000\n",
    "        \n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag2idx[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for fea in feas:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.num_class):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = fea[next_tag].view(\n",
    "                    1, -1).expand(1, self.num_class)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag2idx[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, batch):\n",
    "        out = self.embed(batch)\n",
    "        out, _ = self.rnn(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag2idx[START_TAG]], dtype=torch.long), tags])\n",
    "        for i, fea in enumerate(feas):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + fea[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag2idx[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "    \n",
    "    \n",
    "    def _viterbi_decode(self, feas):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.num_class), -10000.)\n",
    "        init_vvars[0][self.tag2idx[START_TAG]] = 0\n",
    "        \n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for fea in feas:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "            \n",
    "            for next_tag in range(self.num_class):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "        \n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag2idx[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "        \n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag2idx[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "                \n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score    \n",
    "                \n",
    "    def forward(self, batch):\n",
    "        lstm_feas = self._get_lstm_features(batch)\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feas)\n",
    "        return score, tagseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4fdd6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = nn.Parameter(torch.randn(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f312f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions.data[:, tag2idx[STOP_TAG]] = -10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f43f1813",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load(cache_dir + \"embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e151e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "tag2idx.update({START_TAG: 9, STOP_TAG: 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f345ab08",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PosixPath' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-8a412efe1888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = SeqClassifier(tag2idx=tag_idx_path, embeddings=embeddings, hidden_size=256, num_layers=2, dropout=0, \n\u001b[0;32m----> 2\u001b[0;31m                       bidirectional=True, num_class=11)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-6283244e95e8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tag2idx, embeddings, hidden_size, num_layers, dropout, bidirectional, num_class)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# These two statements enforce the constraint that we never transfer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# to the start tag and we never transfer from the stop tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTART_TAG\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTOP_TAG\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PosixPath' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model = SeqClassifier(tag2idx=tag_idx_path, embeddings=embeddings, hidden_size=256, num_layers=2, dropout=0, \n",
    "                      bidirectional=True, num_class=11)\n",
    "for i, batch in enumerate(train_loader):\n",
    "    data = batch[0]\n",
    "    label = batch[1]\n",
    "    pred = model(data)\n",
    "#     pclass = pred.argmax(dim=2)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa42f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_joint_acc(pred, label):\n",
    "    pclass = pred.argmax(dim=2)\n",
    "    correct = 0\n",
    "    for i in range(len(label)):\n",
    "        s_label = label[i][label[i]!=-100]\n",
    "        length = len(s_label)\n",
    "        if (s_label==pclass[i][:length]).all():\n",
    "            correct += 1\n",
    "    jacc = correct / len(label)\n",
    "    return jacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "419a4a2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/100] 5.72 sec(s) Train Loss: 1.5706 Joint_Acc: 0.3945| Val loss: 1.5539 Joint_Acc: 0.4056\n",
      "[002/100] 5.58 sec(s) Train Loss: 1.5571 Joint_Acc: 0.4015| Val loss: 1.5539 Joint_Acc: 0.4056\n",
      "[003/100] 5.71 sec(s) Train Loss: 1.5575 Joint_Acc: 0.4018| Val loss: 1.5538 Joint_Acc: 0.4056\n",
      "[004/100] 5.72 sec(s) Train Loss: 1.5555 Joint_Acc: 0.4015| Val loss: 1.5452 Joint_Acc: 0.4056\n",
      "[005/100] 5.50 sec(s) Train Loss: 1.5236 Joint_Acc: 0.4407| Val loss: 1.4874 Joint_Acc: 0.5192\n",
      "[006/100] 5.70 sec(s) Train Loss: 1.4893 Joint_Acc: 0.5383| Val loss: 1.4731 Joint_Acc: 0.5507\n",
      "[007/100] 5.45 sec(s) Train Loss: 1.4586 Joint_Acc: 0.6283| Val loss: 1.4502 Joint_Acc: 0.6503\n",
      "[008/100] 5.69 sec(s) Train Loss: 1.4466 Joint_Acc: 0.6789| Val loss: 1.4484 Joint_Acc: 0.6409\n",
      "[009/100] 5.85 sec(s) Train Loss: 1.4407 Joint_Acc: 0.7021| Val loss: 1.4313 Joint_Acc: 0.6711\n",
      "[010/100] 5.87 sec(s) Train Loss: 1.4154 Joint_Acc: 0.7576| Val loss: 1.4216 Joint_Acc: 0.7283\n",
      "saving model with acc:0.7283\n",
      "[011/100] 5.64 sec(s) Train Loss: 1.4104 Joint_Acc: 0.7818| Val loss: 1.4235 Joint_Acc: 0.7152\n",
      "[012/100] 5.57 sec(s) Train Loss: 1.4075 Joint_Acc: 0.7937| Val loss: 1.4230 Joint_Acc: 0.7144\n",
      "[013/100] 5.49 sec(s) Train Loss: 1.4040 Joint_Acc: 0.8122| Val loss: 1.4187 Joint_Acc: 0.7339\n",
      "saving model with acc:0.7339\n",
      "[014/100] 5.49 sec(s) Train Loss: 1.4014 Joint_Acc: 0.8226| Val loss: 1.4187 Joint_Acc: 0.7344\n",
      "saving model with acc:0.7344\n",
      "[015/100] 6.01 sec(s) Train Loss: 1.4005 Joint_Acc: 0.8242| Val loss: 1.4154 Joint_Acc: 0.7427\n",
      "saving model with acc:0.7427\n",
      "[016/100] 5.46 sec(s) Train Loss: 1.3994 Joint_Acc: 0.8303| Val loss: 1.4130 Joint_Acc: 0.7649\n",
      "saving model with acc:0.7649\n",
      "[017/100] 5.56 sec(s) Train Loss: 1.3984 Joint_Acc: 0.8358| Val loss: 1.4130 Joint_Acc: 0.7647\n",
      "[018/100] 5.52 sec(s) Train Loss: 1.3980 Joint_Acc: 0.8363| Val loss: 1.4156 Joint_Acc: 0.7416\n",
      "[019/100] 5.47 sec(s) Train Loss: 1.3960 Joint_Acc: 0.8496| Val loss: 1.4133 Joint_Acc: 0.7583\n",
      "[020/100] 5.45 sec(s) Train Loss: 1.3947 Joint_Acc: 0.8563| Val loss: 1.4124 Joint_Acc: 0.7666\n",
      "saving model with acc:0.7666\n",
      "[021/100] 5.49 sec(s) Train Loss: 1.3947 Joint_Acc: 0.8562| Val loss: 1.4114 Joint_Acc: 0.7744\n",
      "saving model with acc:0.7744\n",
      "[022/100] 5.55 sec(s) Train Loss: 1.3939 Joint_Acc: 0.8626| Val loss: 1.4119 Joint_Acc: 0.7702\n",
      "[023/100] 5.48 sec(s) Train Loss: 1.3943 Joint_Acc: 0.8595| Val loss: 1.4117 Joint_Acc: 0.7676\n",
      "[024/100] 5.78 sec(s) Train Loss: 1.3958 Joint_Acc: 0.8508| Val loss: 1.4147 Joint_Acc: 0.7495\n",
      "[025/100] 5.45 sec(s) Train Loss: 1.3935 Joint_Acc: 0.8648| Val loss: 1.4103 Joint_Acc: 0.7734\n",
      "[026/100] 5.43 sec(s) Train Loss: 1.3924 Joint_Acc: 0.8725| Val loss: 1.4122 Joint_Acc: 0.7761\n",
      "saving model with acc:0.7761\n",
      "[027/100] 5.69 sec(s) Train Loss: 1.3916 Joint_Acc: 0.8775| Val loss: 1.4120 Joint_Acc: 0.7683\n",
      "[028/100] 5.47 sec(s) Train Loss: 1.3922 Joint_Acc: 0.8723| Val loss: 1.4121 Joint_Acc: 0.7683\n",
      "[029/100] 5.55 sec(s) Train Loss: 1.3918 Joint_Acc: 0.8768| Val loss: 1.4111 Joint_Acc: 0.7703\n",
      "[030/100] 5.59 sec(s) Train Loss: 1.3909 Joint_Acc: 0.8810| Val loss: 1.4123 Joint_Acc: 0.7646\n",
      "[031/100] 5.48 sec(s) Train Loss: 1.3917 Joint_Acc: 0.8761| Val loss: 1.4130 Joint_Acc: 0.7610\n",
      "[032/100] 5.49 sec(s) Train Loss: 1.3914 Joint_Acc: 0.8772| Val loss: 1.4120 Joint_Acc: 0.7649\n",
      "[033/100] 5.48 sec(s) Train Loss: 1.3910 Joint_Acc: 0.8818| Val loss: 1.4123 Joint_Acc: 0.7634\n",
      "[034/100] 5.57 sec(s) Train Loss: 1.3913 Joint_Acc: 0.8796| Val loss: 1.4087 Joint_Acc: 0.7844\n",
      "saving model with acc:0.7844\n",
      "[035/100] 5.47 sec(s) Train Loss: 1.3900 Joint_Acc: 0.8871| Val loss: 1.4101 Joint_Acc: 0.7832\n",
      "[036/100] 5.63 sec(s) Train Loss: 1.3897 Joint_Acc: 0.8898| Val loss: 1.4101 Joint_Acc: 0.7829\n",
      "[037/100] 5.65 sec(s) Train Loss: 1.3902 Joint_Acc: 0.8872| Val loss: 1.4102 Joint_Acc: 0.7739\n",
      "[038/100] 5.47 sec(s) Train Loss: 1.3897 Joint_Acc: 0.8895| Val loss: 1.4107 Joint_Acc: 0.7737\n",
      "[039/100] 5.49 sec(s) Train Loss: 1.3889 Joint_Acc: 0.8944| Val loss: 1.4084 Joint_Acc: 0.7885\n",
      "saving model with acc:0.7885\n",
      "[040/100] 5.47 sec(s) Train Loss: 1.3887 Joint_Acc: 0.8970| Val loss: 1.4096 Joint_Acc: 0.7819\n",
      "[041/100] 5.67 sec(s) Train Loss: 1.3890 Joint_Acc: 0.8944| Val loss: 1.4094 Joint_Acc: 0.7834\n",
      "[042/100] 5.41 sec(s) Train Loss: 1.3885 Joint_Acc: 0.8971| Val loss: 1.4116 Joint_Acc: 0.7741\n",
      "[043/100] 5.53 sec(s) Train Loss: 1.3888 Joint_Acc: 0.8964| Val loss: 1.4125 Joint_Acc: 0.7698\n",
      "[044/100] 5.43 sec(s) Train Loss: 1.3888 Joint_Acc: 0.8945| Val loss: 1.4130 Joint_Acc: 0.7698\n",
      "[045/100] 5.58 sec(s) Train Loss: 1.3884 Joint_Acc: 0.8982| Val loss: 1.4085 Joint_Acc: 0.7909\n",
      "saving model with acc:0.7909\n",
      "[046/100] 5.54 sec(s) Train Loss: 1.3885 Joint_Acc: 0.8981| Val loss: 1.4106 Joint_Acc: 0.7790\n",
      "[047/100] 5.47 sec(s) Train Loss: 1.3891 Joint_Acc: 0.8930| Val loss: 1.4090 Joint_Acc: 0.7900\n",
      "[048/100] 5.58 sec(s) Train Loss: 1.3875 Joint_Acc: 0.9026| Val loss: 1.4101 Joint_Acc: 0.7841\n",
      "[049/100] 5.61 sec(s) Train Loss: 1.3875 Joint_Acc: 0.9039| Val loss: 1.4098 Joint_Acc: 0.7841\n",
      "[050/100] 5.74 sec(s) Train Loss: 1.3871 Joint_Acc: 0.9059| Val loss: 1.4103 Joint_Acc: 0.7695\n",
      "[051/100] 5.87 sec(s) Train Loss: 1.3872 Joint_Acc: 0.9065| Val loss: 1.4093 Joint_Acc: 0.7824\n",
      "[052/100] 5.67 sec(s) Train Loss: 1.3871 Joint_Acc: 0.9064| Val loss: 1.4096 Joint_Acc: 0.7797\n",
      "[053/100] 5.83 sec(s) Train Loss: 1.3870 Joint_Acc: 0.9062| Val loss: 1.4115 Joint_Acc: 0.7724\n",
      "[054/100] 5.54 sec(s) Train Loss: 1.3874 Joint_Acc: 0.9044| Val loss: 1.4088 Joint_Acc: 0.7863\n",
      "[055/100] 5.41 sec(s) Train Loss: 1.3874 Joint_Acc: 0.9034| Val loss: 1.4097 Joint_Acc: 0.7755\n",
      "[056/100] 5.43 sec(s) Train Loss: 1.3875 Joint_Acc: 0.9034| Val loss: 1.4105 Joint_Acc: 0.7712\n",
      "[057/100] 5.42 sec(s) Train Loss: 1.3867 Joint_Acc: 0.9088| Val loss: 1.4107 Joint_Acc: 0.7782\n",
      "[058/100] 5.73 sec(s) Train Loss: 1.3865 Joint_Acc: 0.9102| Val loss: 1.4109 Joint_Acc: 0.7705\n",
      "[059/100] 5.43 sec(s) Train Loss: 1.3872 Joint_Acc: 0.9049| Val loss: 1.4081 Joint_Acc: 0.7866\n",
      "[060/100] 5.41 sec(s) Train Loss: 1.3869 Joint_Acc: 0.9084| Val loss: 1.4081 Joint_Acc: 0.7948\n",
      "saving model with acc:0.7948\n",
      "[061/100] 5.48 sec(s) Train Loss: 1.3869 Joint_Acc: 0.9085| Val loss: 1.4067 Joint_Acc: 0.7956\n",
      "saving model with acc:0.7956\n",
      "[062/100] 5.49 sec(s) Train Loss: 1.3864 Joint_Acc: 0.9109| Val loss: 1.4076 Joint_Acc: 0.7885\n",
      "[063/100] 5.58 sec(s) Train Loss: 1.3863 Joint_Acc: 0.9115| Val loss: 1.4103 Joint_Acc: 0.7864\n",
      "[064/100] 5.53 sec(s) Train Loss: 1.3861 Joint_Acc: 0.9125| Val loss: 1.4083 Joint_Acc: 0.7912\n",
      "[065/100] 5.82 sec(s) Train Loss: 1.3860 Joint_Acc: 0.9132| Val loss: 1.4095 Joint_Acc: 0.7754\n",
      "[066/100] 5.44 sec(s) Train Loss: 1.3861 Joint_Acc: 0.9124| Val loss: 1.4080 Joint_Acc: 0.7905\n",
      "[067/100] 5.57 sec(s) Train Loss: 1.3860 Joint_Acc: 0.9136| Val loss: 1.4092 Joint_Acc: 0.7819\n",
      "[068/100] 5.85 sec(s) Train Loss: 1.3862 Joint_Acc: 0.9117| Val loss: 1.4107 Joint_Acc: 0.7780\n",
      "[069/100] 5.69 sec(s) Train Loss: 1.3870 Joint_Acc: 0.9072| Val loss: 1.4115 Joint_Acc: 0.7705\n",
      "[070/100] 5.66 sec(s) Train Loss: 1.3864 Joint_Acc: 0.9116| Val loss: 1.4097 Joint_Acc: 0.7849\n",
      "[071/100] 5.48 sec(s) Train Loss: 1.3864 Joint_Acc: 0.9103| Val loss: 1.4091 Joint_Acc: 0.7739\n",
      "[072/100] 5.63 sec(s) Train Loss: 1.3870 Joint_Acc: 0.9068| Val loss: 1.4091 Joint_Acc: 0.7841\n",
      "[073/100] 5.51 sec(s) Train Loss: 1.3863 Joint_Acc: 0.9123| Val loss: 1.4100 Joint_Acc: 0.7841\n",
      "[074/100] 5.57 sec(s) Train Loss: 1.3861 Joint_Acc: 0.9129| Val loss: 1.4089 Joint_Acc: 0.7858\n",
      "[075/100] 5.49 sec(s) Train Loss: 1.3862 Joint_Acc: 0.9137| Val loss: 1.4093 Joint_Acc: 0.7807\n",
      "[076/100] 5.76 sec(s) Train Loss: 1.3862 Joint_Acc: 0.9130| Val loss: 1.4087 Joint_Acc: 0.7866\n",
      "[077/100] 5.75 sec(s) Train Loss: 1.3859 Joint_Acc: 0.9147| Val loss: 1.4105 Joint_Acc: 0.7819\n",
      "[078/100] 5.66 sec(s) Train Loss: 1.3858 Joint_Acc: 0.9159| Val loss: 1.4116 Joint_Acc: 0.7778\n",
      "[079/100] 5.49 sec(s) Train Loss: 1.3874 Joint_Acc: 0.9044| Val loss: 1.4103 Joint_Acc: 0.7800\n",
      "[080/100] 5.55 sec(s) Train Loss: 1.3874 Joint_Acc: 0.9061| Val loss: 1.4103 Joint_Acc: 0.7732\n",
      "[081/100] 5.50 sec(s) Train Loss: 1.3877 Joint_Acc: 0.9022| Val loss: 1.4082 Joint_Acc: 0.7895\n",
      "[082/100] 5.52 sec(s) Train Loss: 1.3865 Joint_Acc: 0.9107| Val loss: 1.4085 Joint_Acc: 0.7854\n",
      "[083/100] 5.79 sec(s) Train Loss: 1.3859 Joint_Acc: 0.9150| Val loss: 1.4086 Joint_Acc: 0.7888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[084/100] 5.58 sec(s) Train Loss: 1.3855 Joint_Acc: 0.9167| Val loss: 1.4064 Joint_Acc: 0.8007\n",
      "saving model with acc:0.8007\n",
      "[085/100] 5.69 sec(s) Train Loss: 1.3855 Joint_Acc: 0.9170| Val loss: 1.4078 Joint_Acc: 0.7907\n",
      "[086/100] 5.82 sec(s) Train Loss: 1.3855 Joint_Acc: 0.9170| Val loss: 1.4078 Joint_Acc: 0.7903\n",
      "[087/100] 5.60 sec(s) Train Loss: 1.3849 Joint_Acc: 0.9209| Val loss: 1.4079 Joint_Acc: 0.7921\n",
      "[088/100] 5.40 sec(s) Train Loss: 1.3853 Joint_Acc: 0.9179| Val loss: 1.4078 Joint_Acc: 0.7912\n",
      "[089/100] 5.49 sec(s) Train Loss: 1.3851 Joint_Acc: 0.9198| Val loss: 1.4076 Joint_Acc: 0.7917\n",
      "[090/100] 5.50 sec(s) Train Loss: 1.3852 Joint_Acc: 0.9193| Val loss: 1.4074 Joint_Acc: 0.8000\n",
      "[091/100] 5.55 sec(s) Train Loss: 1.3853 Joint_Acc: 0.9182| Val loss: 1.4098 Joint_Acc: 0.7766\n",
      "[092/100] 5.63 sec(s) Train Loss: 1.3855 Joint_Acc: 0.9176| Val loss: 1.4074 Joint_Acc: 0.7915\n",
      "[093/100] 5.51 sec(s) Train Loss: 1.3852 Joint_Acc: 0.9185| Val loss: 1.4077 Joint_Acc: 0.7956\n",
      "[094/100] 5.53 sec(s) Train Loss: 1.3851 Joint_Acc: 0.9197| Val loss: 1.4065 Joint_Acc: 0.7948\n",
      "[095/100] 5.84 sec(s) Train Loss: 1.3847 Joint_Acc: 0.9224| Val loss: 1.4061 Joint_Acc: 0.8003\n",
      "[096/100] 5.43 sec(s) Train Loss: 1.3853 Joint_Acc: 0.9181| Val loss: 1.4082 Joint_Acc: 0.7907\n",
      "[097/100] 5.80 sec(s) Train Loss: 1.3861 Joint_Acc: 0.9131| Val loss: 1.4097 Joint_Acc: 0.7773\n",
      "[098/100] 5.65 sec(s) Train Loss: 1.3857 Joint_Acc: 0.9163| Val loss: 1.4098 Joint_Acc: 0.7691\n",
      "[099/100] 5.57 sec(s) Train Loss: 1.3855 Joint_Acc: 0.9174| Val loss: 1.4089 Joint_Acc: 0.7846\n",
      "[100/100] 5.74 sec(s) Train Loss: 1.3850 Joint_Acc: 0.9201| Val loss: 1.4070 Joint_Acc: 0.7958\n"
     ]
    }
   ],
   "source": [
    "embeddings = torch.load(cache_dir + \"embeddings.pt\")\n",
    "\n",
    "model = SeqClassifier(embeddings=embeddings, hidden_size=256, num_layers=2, dropout=0.2, bidirectional=True, num_class=9)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "epochs = 100\n",
    "best_jacc = 0.7\n",
    "# epoch_pbar = trange(epochs, desc=\"Epoch\")\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_jacc = 0\n",
    "    train_len = 0\n",
    "    val_loss = 0\n",
    "    val_jacc = 0\n",
    "    val_len = 0\n",
    "    \n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = batch[0].to(device)\n",
    "        label = batch[1].to(device)\n",
    "        pred = model(data)\n",
    "        _pred = pred.permute(0, 2, 1)\n",
    "        loss = criterion(_pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_jacc += cal_joint_acc(pred, label)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            data = batch[0].to(device)\n",
    "            label = batch[1].to(device)\n",
    "            pred = model(data)\n",
    "            _pred = pred.permute(0, 2, 1)\n",
    "            loss = criterion(_pred, label)\n",
    "            val_loss += loss.item()\n",
    "            val_jacc += cal_joint_acc(pred, label)\n",
    "        \n",
    "    print('[%03d/%03d] %2.2f sec(s) Train Loss: %.4f Joint_Acc: %.4f| Val loss: %.4f Joint_Acc: %.4f' % \\\n",
    "            (epoch + 1, epochs, time.time()-epoch_start_time, \\\n",
    "             train_loss/train_loader.__len__(), train_jacc/train_loader.__len__(), \\\n",
    "             val_loss/val_loader.__len__(), val_jacc/val_loader.__len__()))\n",
    "    \n",
    "    if val_jacc/val_loader.__len__() >= best_jacc:\n",
    "        best_jacc = val_jacc/val_loader.__len__()\n",
    "        torch.save(model.state_dict(), \"/data/NFS/andy/course/ADL/hw1/slot_weights2.pt\")\n",
    "        print(\"saving model with acc:%.4f\" %(best_jacc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
