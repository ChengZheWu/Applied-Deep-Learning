{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc39d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset, DatasetDict\n",
    "from eval import *\n",
    "from transformers import default_data_collator\n",
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "dir_path = \"/data/NFS/andy/course/ADL/hw2/\"\n",
    "data_path = dir_path + \"/dataset/train.json\"\n",
    "context_path = dir_path + \"/dataset/context.json\"\n",
    "weights_path = dir_path + \"/qa_weigths/\"\n",
    "\n",
    "# model_checkpoint = \"bert-base-chinese\"\n",
    "# model_checkpoint = \"hfl/chinese-roberta-wwm-ext\"\n",
    "model_checkpoint = \"hfl/chinese-macbert-large\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "squad_v2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead5f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples\n",
    "\n",
    "def prepare_validation_features(examples):\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
    "        # position is part of the context or not.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    # Build a map example to its corresponding features.\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    # The dictionaries we have to fill.\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # Logging.\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    # Let's loop over all the examples!\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        # Those are the indices of the features associated to the current example.\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None # Only used if squad_v2 is True.\n",
    "        valid_answers = []\n",
    "        \n",
    "        context = example[\"context\"]\n",
    "        # Looping through all the features associated to the current example.\n",
    "        for feature_index in feature_indices:\n",
    "            # We grab the predictions of the model for this feature.\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
    "            # context.\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            # Update minimum null prediction.\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                    # to part of the input_ids that are not in the context.\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        \n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
    "            # failure.\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bcae81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading /data/NFS/andy/course/ADL/hw2//dataset/train.json...done\n",
      "[*] Loading /data/NFS/andy/course/ADL/hw2//dataset/context.json...done\n"
     ]
    }
   ],
   "source": [
    "data = load_json(data_path)\n",
    "context = load_json(context_path)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i][\"answers\"] = {\"answer_start\":[data[i][\"answers\"][0][\"start\"]], \"text\": [data[i][\"answers\"][0][\"text\"]]}\n",
    "    \n",
    "length = int(len(data)*0.8)\n",
    "train_data = {\"id\":[], \"question\":[], \"context\":[], \"answers\":[]}\n",
    "val_data = {\"id\":[], \"question\":[], \"context\":[], \"answers\":[]}\n",
    "for sub in data[:length]:\n",
    "    train_data[\"id\"].append(sub[\"id\"])\n",
    "    train_data[\"question\"].append(sub[\"question\"])\n",
    "    train_data[\"context\"].append(context[sub[\"relevant\"]])\n",
    "    train_data[\"answers\"].append(sub[\"answers\"])\n",
    "for sub in data[length:]:\n",
    "    val_data[\"id\"].append(sub[\"id\"])\n",
    "    val_data[\"question\"].append(sub[\"question\"])\n",
    "    val_data[\"context\"].append(context[sub[\"relevant\"]])\n",
    "    val_data[\"answers\"].append(sub[\"answers\"])\n",
    "    \n",
    "datasets = DatasetDict({\"train\":Dataset.from_dict(train_data), \"val\":Dataset.from_dict(val_data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28085a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44896f267c8a409bb7b9c452d38131fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b165e24cfe40e29dae96886007ab91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n",
    "\n",
    "max_length = 384 # The maximum length of a feature (question and context)\n",
    "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\n",
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "tokenized_datasets = datasets.map(prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6cee1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-macbert-large were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at hfl/chinese-macbert-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7dd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "data_collator = default_data_collator\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = \"./qa_checkpoints\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps = 32,\n",
    "    load_best_model_at_end = True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"val\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ce007b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1626' max='1626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1626/1626 6:00:19, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.643900</td>\n",
       "      <td>0.357328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.348612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.110900</td>\n",
       "      <td>0.455167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1626, training_loss=0.3055918401457727, metrics={'train_runtime': 21631.7911, 'train_samples_per_second': 0.075, 'total_flos': 7.785702630376243e+16, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e90802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff18d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0b13d06f7842e39852659f7c6edcab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validation_features = datasets[\"val\"].map(prepare_validation_features, batched=True, \n",
    "                                          remove_columns=datasets[\"val\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d2dd74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4330' max='4330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4330/4330 09:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0398c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/4882 [00:00<01:00, 79.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 4882 example predictions split into 8659 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4882/4882 [01:07<00:00, 72.38it/s]\n"
     ]
    }
   ],
   "source": [
    "final_predictions = postprocess_qa_predictions(datasets[\"val\"], validation_features, raw_predictions.predictions)\n",
    "\n",
    "submission = {}\n",
    "for i in range(len(datasets[\"val\"])):\n",
    "    submission[datasets[\"val\"][i][\"id\"]] = final_predictions[datasets[\"val\"][i][\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4790dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading /data/NFS/andy/course/ADL/hw2//dataset/train.json...done\n"
     ]
    }
   ],
   "source": [
    "data = load_json(data_path)\n",
    "length = int(len(data)*0.8)\n",
    "data_val = data[length:]\n",
    "answers = collect_answers(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3298a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1550f26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*] Evaluating: 100%|██████████| 4882/4882 [00:58<00:00, 83.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 4882, 'em': 0.865219172470299, 'f1': 0.9246757741238317}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = compute_metrics(answers, submission, tokenizer)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8c4f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(train_metirc, val_metric, metric_name, loss=False):\n",
    "    plt.plot(train_metirc, label='train_%s' %metric_name)\n",
    "    plt.plot(val_metric, label=\"val_%s\" %metric_name)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.xticks([0, 1, 2],[1, 2, 3])\n",
    "    if loss:\n",
    "        plt.legend(loc='upper right')\n",
    "    else:\n",
    "        plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91dbd8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([0.643900, 0.218300, 0.110900], [0.357328, 0.348612, 0.455167], \"loss\", True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
