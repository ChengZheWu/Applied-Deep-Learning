# Final Project
* Dialogue State Tracking (DST)  
* Natural language generation (NLG)  
![Task-Oriented Dialogue Pipeline](https://github.com/ChengZheWu/Applied-Deep-Learning/blob/main/final_project/Task-Oriented%20Dialogue%20Pipeline.png)  

# Dataset
miltiWOZ & dstc8

# DST
* text classification  
* question answering  
![DST](https://github.com/ChengZheWu/Applied-Deep-Learning/blob/main/final_project/DST.png)  

## text classification
Model                    |Acc(%) |
:-----------------------:|:-----:|
BERT (bert-base-uncased) |96     |

## question answering
Model                    |EM(%)  |F1(%)  |
:-----------------------:|:-----:|:-----:|
BERT (bert-base-uncased) |69.1   |65.2

# NLG
* chit chat generation  
* Arranger  
![chit chat](https://github.com/ChengZheWu/Applied-Deep-Learning/blob/main/final_project/chit%20chat.png)
![NLG](https://github.com/ChengZheWu/Applied-Deep-Learning/blob/main/final_project/NLG.png)  

## chit chat generation
Model                                                           |Token Acc(%) |
:--------------------------------------------------------------:|:-----------:|
Parlai中的Tutorial Transformer Generator(90M transformer model) |75.1     

## Arranger
Model   |Acc(%) |
:------:|:-----:|
RoBERTa |66.31  |

## Result
![result](https://github.com/ChengZheWu/Applied-Deep-Learning/blob/main/final_project/result.png)  

